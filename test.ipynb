{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 637 (3182720844.py, line 638)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 638\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m\"\"\"\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m expected an indented block after function definition on line 637\n"
     ]
    }
   ],
   "source": [
    "# code ที่ไว้ทำ model\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LambdaCallback\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import librosa\n",
    "import librosa.display\n",
    "import joblib\n",
    "import pickle\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "def extract_advanced_features(audio_path, max_length=6.0):\n",
    "    \"\"\"\n",
    "    สกัดคุณลักษณะที่หลากหลายจากไฟล์เสียง\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # โหลดไฟล์เสียง\n",
    "        y, sr = librosa.load(audio_path, sr=22050)\n",
    "        \n",
    "        # ปรับความยาวเสียงให้เท่ากัน\n",
    "        target_length = int(max_length * sr)\n",
    "        \n",
    "        if len(y) > target_length:\n",
    "            y = y[:target_length]\n",
    "        else:\n",
    "            # Pad with zeros\n",
    "            padding = target_length - len(y)\n",
    "            y = np.pad(y, (0, padding), 'constant')\n",
    "        \n",
    "        # 1. Mel Spectrogram - ให้ความสำคัญมากที่สุด\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, \n",
    "                                                fmax=8000, n_fft=2048, hop_length=512)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        \n",
    "        # 2. MFCC - Mel-frequency cepstral coefficients\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "        delta_mfcc = librosa.feature.delta(mfcc)\n",
    "        delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
    "        \n",
    "        # รวม features แบบมัลติ-แชนแนล (3 ช่อง)\n",
    "        # Normalize features\n",
    "        mel_spec_norm = (mel_spec_db - np.mean(mel_spec_db)) / (np.std(mel_spec_db) + 1e-10)\n",
    "        mfcc_norm = (mfcc - np.mean(mfcc)) / (np.std(mfcc) + 1e-10)\n",
    "        delta_norm = (delta_mfcc - np.mean(delta_mfcc)) / (np.std(delta_mfcc) + 1e-10)\n",
    "        \n",
    "        # ปรับขนาดให้เท่ากัน\n",
    "        target_shape = (128, 128)\n",
    "        mel_spec_resized = cv2.resize(mel_spec_norm, (target_shape[1], target_shape[0]))\n",
    "        mfcc_resized = cv2.resize(mfcc_norm, (target_shape[1], target_shape[0]))\n",
    "        delta_resized = cv2.resize(delta_norm, (target_shape[1], target_shape[0]))\n",
    "        \n",
    "        # รวมเป็นภาพ 3 ช่อง (RGB-like)\n",
    "        feature_image = np.stack([mel_spec_resized, mfcc_resized, delta_resized], axis=-1)\n",
    "        \n",
    "        # ทำให้ค่าอยู่ระหว่าง 0-1\n",
    "        feature_image = (feature_image - feature_image.min()) / (feature_image.max() - feature_image.min() + 1e-10)\n",
    "        \n",
    "        return feature_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features from {audio_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def load_and_preprocess_data(data_dir, selected_accents, max_samples=150):\n",
    "    X = []\n",
    "    y = []\n",
    "    file_paths = []\n",
    "    \n",
    "    print(\"กำลังโหลดข้อมูลเสียง...\")\n",
    "    print(f\"โฟลเดอร์ข้อมูล: {data_dir}\")\n",
    "    \n",
    "    # ตรวจสอบว่าโฟลเดอร์ข้อมูลมีอยู่จริง\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"ไม่พบโฟลเดอร์ข้อมูล: {data_dir}\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # สร้าง Label Encoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(selected_accents)\n",
    "    \n",
    "    # โหลดข้อมูลจากแต่ละสำเนียงที่เลือก\n",
    "    total_files_found = 0\n",
    "    for accent in selected_accents:\n",
    "        accent_dir = os.path.join(data_dir, accent)\n",
    "        if not os.path.isdir(accent_dir):\n",
    "            print(f\"ไม่พบโฟลเดอร์สำหรับสำเนียง {accent} ที่ {accent_dir}\")\n",
    "            continue\n",
    "        \n",
    "        accent_files = [os.path.join(accent_dir, f) for f in os.listdir(accent_dir) \n",
    "                        if f.endswith('.wav') or f.endswith('.mp3')]\n",
    "        \n",
    "        total_files_found += len(accent_files)\n",
    "        \n",
    "        # จำกัดจำนวนตัวอย่างต่อสำเนียง\n",
    "        if max_samples and len(accent_files) > max_samples:\n",
    "            accent_files = accent_files[:max_samples]\n",
    "        \n",
    "        print(f\"กำลังประมวลผลสำเนียง {accent}: พบ {len(accent_files)} ไฟล์\")\n",
    "        \n",
    "        files_processed = 0\n",
    "        for file_path in accent_files:\n",
    "            features = extract_advanced_features(file_path)\n",
    "            if features is not None:\n",
    "                X.append(features)\n",
    "                y.append(accent)\n",
    "                file_paths.append(file_path)\n",
    "                files_processed += 1\n",
    "        \n",
    "        print(f\"  - ประมวลผลสำเร็จ {files_processed} ไฟล์\")\n",
    "    \n",
    "    print(f\"พบไฟล์เสียงทั้งหมด: {total_files_found}\")\n",
    "    print(f\"ประมวลผลสำเร็จ: {len(X)} ไฟล์\")\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        print(\"ไม่มีข้อมูลที่ประมวลผลได้ โปรดตรวจสอบข้อมูลเสียงของคุณ\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # แปลง list เป็น numpy array\n",
    "    X = np.array(X)\n",
    "    \n",
    "    # แปลงป้ายกำกับเป็น one-hot encoding\n",
    "    y_encoded = label_encoder.transform(y)\n",
    "    y_one_hot = to_categorical(y_encoded)\n",
    "    \n",
    "    print(f\"โหลดข้อมูลเสร็จสิ้น: {X.shape[0]} ตัวอย่าง, คุณลักษณะ shape: {X.shape[1:]}\")\n",
    "    \n",
    "    return X, y_one_hot, label_encoder, file_paths\n",
    "def build_cnn_rnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    สร้างโมเดลแบบผสมผสาน CNN + RNN สำหรับการตรวจจับสำเนียง\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # CNN Blocks - สกัดคุณลักษณะเชิงพื้นที่\n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    # Reshape เพื่อให้เข้ากับ RNN\n",
    "    reshape_dim = K.int_shape(x)\n",
    "    x = Reshape((reshape_dim[1], reshape_dim[2] * reshape_dim[3]))(x)\n",
    "    \n",
    "    # RNN Layers - จับลักษณะเชิงลำดับเวลา\n",
    "    x = Bidirectional(GRU(128, return_sequences=True))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Bidirectional(GRU(128))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # Global Features\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0003),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "def residual_block(x, filters, kernel_size=3):\n",
    "    \"\"\"\n",
    "    สร้างบล็อก Residual สำหรับโมเดล ResNet\n",
    "    \"\"\"\n",
    "    # แบบ Residual Block ช่วยให้เทรนโมเดลลึกได้มากขึ้น\n",
    "    y = Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = Conv2D(filters, kernel_size, padding='same')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    \n",
    "    # สร้าง shortcut connection\n",
    "    if K.int_shape(x)[-1] != filters:\n",
    "        x = Conv2D(filters, 1, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "    \n",
    "    out = Add()([x, y])\n",
    "    out = Activation('relu')(out)\n",
    "    return out\n",
    "\n",
    "def build_resnet_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    สร้างโมเดลแบบ ResNet สำหรับการตรวจจับสำเนียง\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Initial Conv Layer\n",
    "    x = Conv2D(32, 7, strides=2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    \n",
    "    # Residual blocks\n",
    "    x = residual_block(x, 32)\n",
    "    x = residual_block(x, 32)\n",
    "    x = MaxPooling2D(2, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = residual_block(x, 64)\n",
    "    x = residual_block(x, 64)\n",
    "    x = MaxPooling2D(2, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = residual_block(x, 128)\n",
    "    x = residual_block(x, 128)\n",
    "    \n",
    "    # Final layers\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0003),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "def positional_encoding(position, d_model):\n",
    "    \"\"\"\n",
    "    สร้าง positional encoding สำหรับ Transformer\n",
    "    \"\"\"\n",
    "    def get_angles(pos, i, d_model):\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "        return pos * angle_rates\n",
    "    \n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                            np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model)\n",
    "    \n",
    "    # sin ใช้สำหรับตำแหน่งคู่ (0, 2, 4, ...)\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    \n",
    "    # cos ใช้สำหรับตำแหน่งคี่ (1, 3, 5, ...)\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "    \"\"\"\n",
    "    คำนวณ scaled dot product attention\n",
    "    \"\"\"\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "    \n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    \n",
    "    # add mask (optional)\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "    \n",
    "    # softmax normalization\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "    \n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    \n",
    "    return output, attention_weights\n",
    "\n",
    "class MultiHeadAttention(Layer):\n",
    "    \"\"\"\n",
    "    Multi-head attention layer\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.wq = Dense(d_model)\n",
    "        self.wk = Dense(d_model)\n",
    "        self.wv = Dense(d_model)\n",
    "        \n",
    "        self.dense = Dense(d_model)\n",
    "    \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask=None):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        \n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                        (batch_size, -1, self.d_model))\n",
    "        \n",
    "        output = self.dense(concat_attention)\n",
    "        \n",
    "        return output\n",
    "\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    \"\"\"\n",
    "    Simple feed forward network for transformer\n",
    "    \"\"\"\n",
    "    return Sequential([\n",
    "        Dense(dff, activation='relu'),\n",
    "        Dense(d_model)\n",
    "    ])\n",
    "\n",
    "class EncoderLayer(Layer):\n",
    "    \"\"\"\n",
    "    Encoder layer for transformer\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training=True):\n",
    "        attn_output = self.mha(x, x, x)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        \n",
    "        return out2\n",
    "\n",
    "def build_transformer_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    สร้างโมเดล Transformer-based สำหรับการตรวจจับสำเนียง\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # ใช้ CNN เพื่อสกัดคุณลักษณะ\n",
    "    x = Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    \n",
    "    x = Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    \n",
    "    x = Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    \n",
    "    # Reshape สำหรับ Transformer\n",
    "    shape_before_flatten = K.int_shape(x)\n",
    "    x = Reshape((shape_before_flatten[1] * shape_before_flatten[2], shape_before_flatten[3]))(x)\n",
    "    \n",
    "    # โปรเจคชั่นเป็นมิติของ Transformer\n",
    "    d_model = 128\n",
    "    x = Dense(d_model)(x)\n",
    "    \n",
    "    # เพิ่ม positional encoding\n",
    "    seq_len = shape_before_flatten[1] * shape_before_flatten[2]\n",
    "    pos_encoding = positional_encoding(seq_len, d_model)\n",
    "    x = x + pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    # Dropout\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # Transformer encoder layers\n",
    "    num_layers = 2\n",
    "    for i in range(num_layers):\n",
    "        x = EncoderLayer(d_model=d_model, num_heads=4, dff=256, rate=0.2)(x)\n",
    "    \n",
    "    # Global pooling\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Final layers\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "def train_model_with_advanced_techniques(model, X_train, y_train, X_val, y_val, epochs=200, batch_size=32, model_path='model.h5'):\n",
    "    \"\"\"\n",
    "    ฝึกสอนโมเดลด้วยเทคนิคขั้นสูงเพื่อเพิ่มประสิทธิภาพ\n",
    "    \"\"\"\n",
    "    # ระบบ Callbacks ที่หลากหลาย\n",
    "    callbacks = [\n",
    "        # บันทึกโมเดลที่ดีที่สุด\n",
    "        ModelCheckpoint(\n",
    "            filepath=model_path,\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        # ปรับลด learning rate เมื่อประสิทธิภาพไม่ดีขึ้น\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        ),\n",
    "        # หยุดการฝึกสอนเมื่อไม่มีการพัฒนา\n",
    "        EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=30,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        # บันทึก learning rate ในแต่ละ epoch\n",
    "        LambdaCallback(\n",
    "            on_epoch_end=lambda epoch, logs: logs.update({'learning_rate': float(K.get_value(model.optimizer.learning_rate))})\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Class weight balancing สำหรับข้อมูลที่ไม่สมดุล\n",
    "    # คำนวณน้ำหนักของแต่ละคลาส\n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(np.argmax(y_train, axis=1)),\n",
    "        y=np.argmax(y_train, axis=1)\n",
    "    )\n",
    "    class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "    \n",
    "    # ฝึกสอนโมเดล\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weight_dict,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # โหลดโมเดลที่ดีที่สุด\n",
    "    best_model = load_model(model_path)\n",
    "    \n",
    "    return history, best_model\n",
    "def evaluate_and_visualize(model, X_test, y_test, class_names, label_encoder, history=None, is_ensemble=False):\n",
    "    \"\"\"\n",
    "    ประเมินโมเดลและแสดงผลด้วยภาพ\n",
    "    \"\"\"\n",
    "    # ทำนายด้วยชุดข้อมูลทดสอบ\n",
    "    if is_ensemble:\n",
    "        y_pred_probs = ensemble_predict(model, X_test)\n",
    "    else:\n",
    "        # ประเมินโมเดล\n",
    "        test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "        print(f\"\\nความแม่นยำบนชุดข้อมูลทดสอบ: {test_accuracy * 100:.2f}%\")\n",
    "        y_pred_probs = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # แสดงผลการประเมิน\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    print(\"\\n===== รายงานประสิทธิภาพโมเดล =====\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "    \n",
    "    print(\"\\n===== รายงานการจำแนกประเภทโดยละเอียด =====\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "    \n",
    "    # แสดง Confusion Matrix ด้วย Seaborn\n",
    "    plt.figure(figsize=(14, 12))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # แสดงทั้งจำนวนและเปอร์เซ็นต์\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    \n",
    "    # สร้าง custom annotation\n",
    "    annot = np.empty_like(cm, dtype=str)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            annot[i, j] = f'{cm[i, j]}\\n({cm_percent[i, j]:.1f}%)'\n",
    "    \n",
    "    ax = sns.heatmap(cm, annot=cm, fmt='', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    \n",
    "    # ปรับปรุงความสวยงาม\n",
    "    plt.title('Confusion Matrix', fontsize=18, pad=20)\n",
    "    plt.xlabel('Predicted Label', fontsize=14)\n",
    "    plt.ylabel('True Label', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    # แสดงกราฟประวัติการฝึกสอน\n",
    "    if history:\n",
    "        # กราฟความแม่นยำและ loss\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        \n",
    "        # กราฟความแม่นยำ\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['accuracy'], 'o-', linewidth=2, label='Train Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], 'o-', linewidth=2, label='Validation Accuracy')\n",
    "        plt.title('Model Accuracy Over Time', fontsize=16)\n",
    "        plt.xlabel('Epoch', fontsize=14)\n",
    "        plt.ylabel('Accuracy', fontsize=14)\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.legend(fontsize=12)\n",
    "        \n",
    "        # กราฟค่าสูญเสีย\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['loss'], 'o-', linewidth=2, label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], 'o-', linewidth=2, label='Validation Loss')\n",
    "        plt.title('Model Loss Over Time', fontsize=16)\n",
    "        plt.xlabel('Epoch', fontsize=14)\n",
    "        plt.ylabel('Loss', fontsize=14)\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.legend(fontsize=12)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_history.png', dpi=300)\n",
    "        plt.show()\n",
    "        \n",
    "        # กราฟการเปรียบเทียบความแม่นยำรายคลาส\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        \n",
    "        # คำนวณความแม่นยำรายคลาส\n",
    "        class_accuracy = {}\n",
    "        for i, name in enumerate(class_names):\n",
    "            # เลือกเฉพาะตัวอย่างที่เป็นคลาสนั้น\n",
    "            class_indices = np.where(y_true == i)[0]\n",
    "            class_true = y_true[class_indices]\n",
    "            class_pred = y_pred[class_indices]\n",
    "            class_accuracy[name] = accuracy_score(class_true, class_pred) if len(class_indices) > 0 else 0\n",
    "        \n",
    "        # เรียงลำดับคลาสตามความแม่นยำ\n",
    "        sorted_classes = sorted(class_accuracy.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # สร้างกราฟแท่ง\n",
    "        bars = plt.bar(\n",
    "            [name.capitalize() for name, _ in sorted_classes],\n",
    "            [acc * 100 for _, acc in sorted_classes],\n",
    "            color=[plt.cm.Blues(0.5 + 0.5 * i / len(class_names)) for i in range(len(class_names))]\n",
    "        )\n",
    "        \n",
    "        # เพิ่มค่าบนแท่ง\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(\n",
    "                bar.get_x() + bar.get_width()/2.,\n",
    "                height + 1,\n",
    "                f'{height:.1f}%',\n",
    "                ha='center', va='bottom', fontsize=12\n",
    "            )\n",
    "        \n",
    "        plt.title\n",
    "        plt.title('Accuracy by Language/Accent', fontsize=16)\n",
    "        plt.xlabel('Language', fontsize=14)\n",
    "        plt.ylabel('Accuracy (%)', fontsize=14)\n",
    "        plt.ylim(0, 105)\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('accuracy_by_language.png', dpi=300)\n",
    "        plt.show()\n",
    "    \n",
    "    # แสดงตัวอย่างการทำนาย\n",
    "    num_samples = min(5, len(X_test))\n",
    "    sample_indices = np.random.choice(len(X_test), num_samples, replace=False)\n",
    "    \n",
    "    print(\"\\n===== ตัวอย่างการทำนาย =====\")\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        true_class = class_names[np.argmax(y_test[idx])]\n",
    "        pred_probs = y_pred_probs[idx]\n",
    "        \n",
    "        # จัดอันดับการทำนาย\n",
    "        top_indices = np.argsort(pred_probs)[::-1][:3]\n",
    "        \n",
    "        print(f\"\\nตัวอย่างที่ {i+1}:\")\n",
    "        print(f\"สำเนียงจริง: {true_class}\")\n",
    "        \n",
    "        for j, index in enumerate(top_indices):\n",
    "            print(f\"อันดับ {j+1}: {class_names[index]} - {pred_probs[index]*100:.1f}%\")\n",
    "        def build_ensemble_models(X, y, num_models=2):  # ลดจำนวนโมเดลจาก 3 เป็น 2\n",
    "    \"\"\"\n",
    "    สร้าง ensemble ของโมเดลหลายตัวเพื่อเพิ่มประสิทธิภาพการทำนาย\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    input_shape = X.shape[1:]\n",
    "    num_classes = y.shape[1]\n",
    "    \n",
    "    for i in range(num_models):\n",
    "        print(f\"กำลังสร้างโมเดลที่ {i+1}/{num_models}...\")\n",
    "        \n",
    "        if i == 0:\n",
    "            # โมเดลแรกใช้ CNN+RNN Hybrid\n",
    "            model = build_cnn_rnn_model(input_shape, num_classes)\n",
    "        else:\n",
    "            # โมเดลที่สองใช้ ResNet\n",
    "            model = build_resnet_model(input_shape, num_classes)\n",
    "        \n",
    "        models.append(model)\n",
    "    \n",
    "    return models\n",
    "\n",
    "def train_ensemble_models(models, X_train, y_train, X_val, y_val, base_model_path='Model/accent_model'):\n",
    "    \"\"\"\n",
    "    ฝึกสอนโมเดล ensemble แต่ละตัว\n",
    "    \"\"\"\n",
    "    trained_models = []\n",
    "    histories = []\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"กำลังฝึกสอนโมเดลที่ {i+1}/{len(models)}...\")\n",
    "        model_path = f\"{base_model_path}_{i+1}.h5\"\n",
    "        \n",
    "        # ฝึกสอนโมเดล\n",
    "        history, trained_model = train_model_with_advanced_techniques(\n",
    "            model, X_train, y_train, X_val, y_val,\n",
    "            epochs=200, batch_size=32, model_path=model_path\n",
    "        )\n",
    "        \n",
    "        trained_models.append(trained_model)\n",
    "        histories.append(history)\n",
    "    \n",
    "    return trained_models, histories\n",
    "\n",
    "def ensemble_predict(models, X):\n",
    "    \"\"\"\n",
    "    ทำนายโดยใช้ ensemble ของโมเดลหลายตัว\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for model in models:\n",
    "        pred = model.predict(X)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # รวมการทำนายจากทุกโมเดลโดยใช้ค่าเฉลี่ย\n",
    "    ensemble_pred = np.mean(predictions, axis=0)\n",
    "    \n",
    "    return ensemble_pred\n",
    "def main():\n",
    "    # กำหนดค่าเริ่มต้น\n",
    "    data_dir = r\"D:\\Y2.2\\Speech_Accent_Detection\\main_datadset\"  # แก้ไขเป็นโฟลเดอร์ที่เก็บข้อมูลเสียง\n",
    "    model_dir = \"Model\"\n",
    "    \n",
    "    # สร้างโฟลเดอร์สำหรับเก็บโมเดล\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # เลือกภาษาที่มีลักษณะเสียงแตกต่างกันชัดเจน\n",
    "    selected_accents = ['thai', 'english', 'mandarin', 'arabic', 'japanese', 'hindi']\n",
    "    \n",
    "    # โหลดข้อมูลและเตรียมพร้อม\n",
    "    result = load_and_preprocess_data(data_dir, selected_accents)\n",
    "    \n",
    "    if result[0] is None:\n",
    "        print(\"ไม่สามารถดำเนินการต่อได้เนื่องจากไม่มีข้อมูล\")\n",
    "        return\n",
    "    \n",
    "    X, y, label_encoder, file_paths = result\n",
    "    \n",
    "    # ดำเนินการต่อไป...  \n",
    "    # บันทึก label encoder ไว้ใช้ในอนาคต\n",
    "    joblib.dump(label_encoder, os.path.join(model_dir, 'label_encoder.pkl'))\n",
    "    \n",
    "    # แบ่งข้อมูลเป็นชุดฝึกสอน, ชุดตรวจสอบ, และชุดทดสอบ\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=np.argmax(y, axis=1))\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=np.argmax(y_train_val, axis=1))\n",
    "    \n",
    "    print(f\"ขนาดข้อมูลฝึกสอน: {X_train.shape[0]} ตัวอย่าง\")\n",
    "    print(f\"ขนาดข้อมูลตรวจสอบ: {X_val.shape[0]} ตัวอย่าง\")\n",
    "    print(f\"ขนาดข้อมูลทดสอบ: {X_test.shape[0]} ตัวอย่าง\")\n",
    "    \n",
    "    # ฝึกสอนโมเดล CNN + RNN hybrid\n",
    "    print(\"\\n===== กำลังฝึกสอนโมเดล CNN + RNN hybrid =====\")\n",
    "    cnn_rnn_model = build_cnn_rnn_model(X_train.shape[1:], y_train.shape[1])\n",
    "    cnn_rnn_history, trained_cnn_rnn_model = train_model_with_advanced_techniques(\n",
    "        cnn_rnn_model, X_train, y_train, X_val, y_val, \n",
    "        epochs=200, batch_size=32, model_path=os.path.join(model_dir, 'accent_cnn_rnn_model.h5')\n",
    "    )\n",
    "    \n",
    "    # ประเมินผลโมเดล CNN + RNN hybrid\n",
    "    print(\"\\n===== ผลลัพธ์การทดสอบโมเดล CNN + RNN hybrid =====\")\n",
    "    class_names = label_encoder.classes_\n",
    "    evaluate_and_visualize(trained_cnn_rnn_model, X_test, y_test, class_names, label_encoder, cnn_rnn_history)\n",
    "    \n",
    "    # ฝึกสอนโมเดล ResNet\n",
    "    print(\"\\n===== กำลังฝึกสอนโมเดล ResNet =====\")\n",
    "    resnet_model = build_resnet_model(X_train.shape[1:], y_train.shape[1])\n",
    "    resnet_history, trained_resnet_model = train_model_with_advanced_techniques(\n",
    "        resnet_model, X_train, y_train, X_val, y_val, \n",
    "        epochs=200, batch_size=32, model_path=os.path.join(model_dir, 'accent_resnet_model.h5')\n",
    "    )\n",
    "    \n",
    "    # ประเมินผลโมเดล ResNet\n",
    "    print(\"\\n===== ผลลัพธ์การทดสอบโมเดล ResNet =====\")\n",
    "    evaluate_and_visualize(trained_resnet_model, X_test, y_test, class_names, label_encoder, resnet_history)\n",
    "    \n",
    "    # สร้างและฝึกสอนโมเดล Ensemble\n",
    "    print(\"\\n===== กำลังสร้างและฝึกสอนโมเดล Ensemble =====\")\n",
    "    ensemble_models = build_ensemble_models(X_train, y_train, num_models=2)\n",
    "    trained_ensemble, ensemble_histories = train_ensemble_models(\n",
    "        ensemble_models, X_train, y_train, X_val, y_val, \n",
    "        base_model_path=os.path.join(model_dir, 'accent_ensemble_model')\n",
    "    )\n",
    "    \n",
    "    # ประเมินผลโมเดล Ensemble\n",
    "    print(\"\\n===== ผลลัพธ์การทดสอบโมเดล Ensemble =====\")\n",
    "    # ทำนายด้วย ensemble\n",
    "    ensemble_preds = ensemble_predict(trained_ensemble, X_test)\n",
    "    y_pred = np.argmax(ensemble_preds, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # แสดงผลการประเมิน\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    print(\"\\n===== รายงานประสิทธิภาพโมเดล Ensemble =====\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "    \n",
    "    print(\"\\n===== รายงานการจำแนกประเภทโดยละเอียด =====\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "    \n",
    "    # แสดง Confusion Matrix สำหรับ Ensemble\n",
    "    plt.figure(figsize=(14, 12))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Ensemble Model Confusion Matrix', fontsize=18, pad=20)\n",
    "    plt.xlabel('Predicted Label', fontsize=14)\n",
    "    plt.ylabel('True Label', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('ensemble_confusion_matrix.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    # เปรียบเทียบความแม่นยำของโมเดลทั้งหมด\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # ทำนายด้วยแต่ละโมเดล\n",
    "    cnn_rnn_preds = trained_cnn_rnn_model.predict(X_test)\n",
    "    cnn_rnn_acc = accuracy_score(np.argmax(y_test, axis=1), np.argmax(cnn_rnn_preds, axis=1))\n",
    "\n",
    "    resnet_preds = trained_resnet_model.predict(X_test)\n",
    "    resnet_acc = accuracy_score(np.argmax(y_test, axis=1), np.argmax(resnet_preds, axis=1))\n",
    "\n",
    "    # ข้อมูลสำหรับกราฟแท่ง\n",
    "    models = ['CNN+RNN', 'ResNet', 'Ensemble']\n",
    "    accuracies = [\n",
    "        cnn_rnn_acc * 100, \n",
    "        resnet_acc * 100,\n",
    "        accuracy * 100\n",
    "    ]\n",
    "\n",
    "    # เพิ่มค่าบนแท่ง\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width()/2.,\n",
    "            height + 1,\n",
    "            f'{height:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=12\n",
    "        )\n",
    "    \n",
    "    plt.title('Model Comparison: Accuracy', fontsize=16)\n",
    "    plt.xlabel('Model', fontsize=14)\n",
    "    plt.ylabel('Accuracy (%)', fontsize=14)\n",
    "    plt.ylim(0, 105)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "    plt.savefig('model_comparison.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nการฝึกสอนและทดสอบโมเดลเสร็จสิ้น\")\n",
    "    def preprocess_audio_file(audio_path, model_dir=\"Model\"):\n",
    "    try:\n",
    "        # สกัดคุณลักษณะจากไฟล์เสียง\n",
    "        features = extract_advanced_features(audio_path)\n",
    "        if features is None:\n",
    "            return None\n",
    "        \n",
    "        # แปลงเป็น numpy array และเพิ่มมิติแบตช์\n",
    "        features = np.expand_dims(features, axis=0)\n",
    "        \n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"เกิดข้อผิดพลาดในการประมวลผลไฟล์เสียง: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def predict_accent(audio_path, model_dir=\"Model\"):\n",
    "    \"\"\"\n",
    "    ทำนายสำเนียงจากไฟล์เสียง\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # โหลด label encoder\n",
    "        label_encoder = joblib.load(os.path.join(model_dir, 'label_encoder.pkl'))\n",
    "        \n",
    "        # โหลดโมเดล ensemble\n",
    "        models = []\n",
    "        for i in range(3):\n",
    "            model_path = os.path.join(model_dir, f'accent_ensemble_model_{i+1}.h5')\n",
    "            if os.path.exists(model_path):\n",
    "                models.append(load_model(model_path))\n",
    "            else:\n",
    "                print(f\"ไม่พบไฟล์โมเดล {model_path}\")\n",
    "        \n",
    "        if len(models) == 0:\n",
    "            # ถ้าไม่มีโมเดล ensemble ให้ใช้โมเดล CNN+RNN แทน\n",
    "            model_path = os.path.join(model_dir, 'accent_cnn_rnn_model.h5')\n",
    "            if os.path.exists(model_path):\n",
    "                model = load_model(model_path)\n",
    "                models = [model]\n",
    "            else:\n",
    "                raise FileNotFoundError(\"ไม่พบไฟล์โมเดล\")\n",
    "        \n",
    "        # ประมวลผลไฟล์เสียง\n",
    "        features = preprocess_audio_file(audio_path, model_dir)\n",
    "        if features is None:\n",
    "            return \"ไม่สามารถประมวลผลไฟล์เสียงได้\"\n",
    "        \n",
    "        # ทำนาย\n",
    "        if len(models) > 1:\n",
    "            # ใช้ ensemble\n",
    "            predictions = []\n",
    "            for model in models:\n",
    "                pred = model.predict(features)\n",
    "                predictions.append(pred)\n",
    "            pred_probs = np.mean(predictions, axis=0)[0]\n",
    "        else:\n",
    "            # ใช้โมเดลเดียว\n",
    "            pred_probs = models[0].predict(features)[0]\n",
    "        \n",
    "        # จัดอันดับผลการทำนาย\n",
    "        top_indices = np.argsort(pred_probs)[::-1]\n",
    "        \n",
    "        # แสดงผลลัพธ์\n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices[:3]):  # แสดง 3 อันดับแรก\n",
    "            accent = label_encoder.classes_[idx]\n",
    "            confidence = pred_probs[idx] * 100\n",
    "            results.append((accent, confidence))\n",
    "        \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"เกิดข้อผิดพลาดในการทำนาย: {str(e)}\")\n",
    "        return \"เกิดข้อผิดพลาดในการทำนาย\"\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
